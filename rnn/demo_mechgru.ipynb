{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a579c52e",
   "metadata": {},
   "source": [
    "# Demo\n",
    "这是一个简化版的Mechformer的demo笔记, 我们将通过搭建一个基于gru单元的神经网络MechGRU，用于解决某种钢材的应力-应变曲线预测，即根据应变序列预测应力序列."
   ]
  },
  {
   "cell_type": "code",
   "id": "54eada3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:33:33.806222Z",
     "start_time": "2024-08-23T08:33:33.801469Z"
    }
   },
   "source": [
    "# 导入主要的包\n",
    "# pytorch相关\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# TensorDataset和DataLoader是pytorch定义的一种数据集类，可以比较方便地处理数据\n",
    "\n",
    "# 辅助包，其中os,math,random一般由python自带\n",
    "# pandas, matplotlib可通过pip或conda安装\n",
    "# pip 安装：\n",
    "# pip install pandas\n",
    "# pip install matplotlib\n",
    "# conda 安装：\n",
    "# conda install pandas\n",
    "# conda install matplotlib\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 如果有gpu，优先加载到gpu上进行训练\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "eccc59d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:25:50.331979Z",
     "start_time": "2024-08-23T08:25:50.325192Z"
    }
   },
   "source": [
    "# 数据前处理和后处理\n",
    "def data_preprocess(input_data, ref):\n",
    "    \"\"\"\n",
    "    在这里定义对数据进行预处理的函数\n",
    "    简化为除以ref的形式，也可以采用更复杂的方式\n",
    "    参数:\n",
    "        input_data(nn.Tensor)\n",
    "    输出:\n",
    "        output_data(nn.Tensor)\n",
    "    \"\"\"\n",
    "    output_data = input_data / ref\n",
    "    return output_data\n",
    "\n",
    "def data_postprocess(input_data, ref):\n",
    "    \"\"\"\n",
    "    在这里定义对数据进行后处理的函数，即还原到原始数据的分布\n",
    "    参数:\n",
    "        input_data(nn.Tensor)\n",
    "    输出:\n",
    "        output_data(nn.Tensor)\n",
    "    \"\"\"\n",
    "    output_data = input_data*ref\n",
    "    return output_data\n",
    "\n",
    "# 构建数据集, 数据集是某种钢材的一批应力-应变滞回曲线，保存为csv格式\n",
    "# 每个csv文件里是一条数据，其中第一列为应变值(src)，第二列为应力值(tgt)\n",
    "# 第一次试验时建议不要修改以下参数\n",
    "# 根据配置和读取数据量的大小，耗时1~5分钟\n",
    "\"\"\"\n",
    "主要参数说明\n",
    "DATA_SIZE: 总数据量，最大为2000\n",
    "TRAIN_SIZE: 训练集数据量，不超过2000\n",
    "TEST_SIZE: 测试集数据量，除了训练数据以外的数据\n",
    "SRC_SIZE: src维度，应变值为标量因此取1\n",
    "TGT_SIZE: tgt维度，应力值为标量因此取1\n",
    "SEQ_START: 序列的起始位置，默认为0\n",
    "SEQ_LEN: 序列的总长度，本数据集的序列最大长度为1001，demo中为简化计算取512\n",
    "src_ref: src的归一化参考值\n",
    "tgt_ref: tgt的归一化参考值\n",
    "data_path: csv数据存放路径，默认为脚本同一目录下的r'data'\n",
    "注意BATCH_SIZE和SEQ_LEN一般受到显存的限制，需要根据配置调整\n",
    "\"\"\"\n",
    "DATA_SIZE = 2048\n",
    "TRAIN_SIZE = 1920\n",
    "TEST_SIZE = DATA_SIZE - TRAIN_SIZE\n",
    "SRC_SIZE = 1\n",
    "TGT_SIZE = 1\n",
    "SEQ_START = 0\n",
    "SEQ_LEN = 512\n",
    "src_ref = 0.01\n",
    "tgt_ref = 300\n",
    "data_path = r'data'\n",
    "\n",
    "def read_data(data_path=data_path):\n",
    "    \"\"\"\n",
    "    请在这里定义一个函数，读取DATA_SIZE数量的CSV文件的数据并转化为张量\n",
    "    其中每个表的第一列应变值存储到srcs中，第二列应力值存储到tgts中\n",
    "    参数：\n",
    "        data_path(str):csv文件的存放路径，默认在同一目录下\n",
    "    输出：\n",
    "        srcs(nn.Tensor):输入序列，即应变路径，要求形状为(DATA_SIZE, SEQ_LEN, SRC_SIZE=1)\n",
    "        tgts(nn.Tensor):输出序列，即应力路径，要求形状为(DATA_SIZE, SEQ_LEN, TGT_SIZE=1)\n",
    "    提示：\n",
    "        使用pandas的模块依次读取每个csv文件的数据为numpy的array，再将array转化为tensor\n",
    "    \"\"\"\n",
    "    ##### your code here #####\n",
    "    return srcs, tgts\n",
    "\n",
    "# 读取数据\n",
    "srcs, tgts = read_data(data_path)\n",
    "\n",
    "# 数据预处理，做简单的归一化\n",
    "srcs, tgts = ?, ?\n",
    "\n",
    "# 检查读取数据的size，如果前后一致表明读取正确\n",
    "print(f\"srcs的shape: {srcs.shape}, 期望的shape: {DATA_SIZE}, {SEQ_LEN}, {SRC_SIZE}\")\n",
    "print(f\"tgts的shape: {tgts.shape}, 期望的shape: {DATA_SIZE}, {SEQ_LEN}, {TGT_SIZE}\")"
   ],
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1441525648.py, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[2], line 73\u001B[1;36m\u001B[0m\n\u001B[1;33m    srcs, tgts = ?, ?\u001B[0m\n\u001B[1;37m                 ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 32\n",
    "\n",
    "# 利用random.shuffle打乱数据以保证随机性\n",
    "indices = torch.randperm(len(srcs))\n",
    "srcs, tgts = srcs[indices], tgts[indices]\n",
    "\n",
    "# 划分训练集和测试集\n",
    "##### your code here #####\n",
    "train_data = ?\n",
    "test_data = ?\n",
    "\n",
    "# 设置DataLoader，用于分批加载数据\n",
    "# 一般而言，总数据量远超计算内存，因此需要分批加载进行训练，也有助于梯度下降\n",
    "##### your code here #####\n",
    "train_loader = ?\n",
    "test_loader = ?\n",
    "print(f\"训练数据集批次: {len(train_loader)}，每批数据量 {TRAIN_BATCH_SIZE}\")\n",
    "print(f\"测试数据集批次: {len(test_loader)}，每批数据量 {TEST_BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc1404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型实现\n",
    "class gruMechformer(nn.Module):\n",
    "    def __init__(self, src_size=1, hidden_size=4, tgt_size=1,num_layers=1, dropout=0, activation=nn.ReLU()):\n",
    "        \"\"\"\n",
    "        在这里初始化模型，结构为输入线性层 + GRU模块 + 输出线性层\n",
    "        一般语言处理中的RNN需要embedding层将词汇转化成词表向量，这里用一个简单的线性层替代\n",
    "        参数：\n",
    "            src_size(int):作为输入序列的特征维度\n",
    "            hidden_size(int):模型的隐层维度\n",
    "            num_layers(int):GRU模块的单元层数，可取1~3\n",
    "            dropout(int):GRU模块的dropout,用于防止过拟合，一般取0~0.1\n",
    "            activation(nn.Module):激活函数，默认选择nn.ReLU()即可\n",
    "        提示：\n",
    "            设计一个输入线性层input_layer\n",
    "            rnn层可调用pytorch的GRU模块\n",
    "            一个输出线性层output_layer\n",
    "            以及激活函数activation\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        ##### your code here #####\n",
    "\n",
    " \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        在这里定义模型的forward函数\n",
    "        参数：\n",
    "            src(torch.Tensor):输入张量，即输入序列，初始形状需为[batch_size, seq_len, src_size]，其中\n",
    "            batch_size:输入每个batch的size\n",
    "            seq_len:输入序列的长度\n",
    "            src_size:src序列的特征维度\n",
    "        输出：\n",
    "            output(torch.Tensor):形状为[batch_size, seq_len, tgt_size]\n",
    "        提示：\n",
    "            输入-线性层-激活函数（可选）-rnn层-激活函数（可选）-线性层-输出\n",
    "        \"\"\"\n",
    "        ##### your code here #####\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model, data_loader, optimizer, lr_scheduler, num_epochs, criterion, num_log):\n",
    "    \"\"\"\n",
    "    在这里定义一个训练模块函数\n",
    "    参数：\n",
    "        model(nn.Module):模型\n",
    "        data_loader(DataLoader):用于加载训练数据的loader\n",
    "        optimizer:训练的优化器\n",
    "        lr_scheduler: 训练learning rate的调整器\n",
    "        criterion:计算loss的损失函数\n",
    "        num_epochs:训练的轮次（所有数据训练一遍作为一轮）\n",
    "        num_log: 每隔num_log个batch输出当前的训练loss\n",
    "    输出：\n",
    "        train_loss(list[float]):记录每个step的训练loss的列表\n",
    "    提示：\n",
    "        对轮次进行循环，每个轮次对数据批次进行循环\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (src, tgt) in enumerate(data_loader):\n",
    "            ##### your code here #####\n",
    "            ##### you need to calculate loss #####\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "            # 输出当前训练状态\n",
    "            if len(train_loss) % num_log == 0:\n",
    "                print(f'[Epoch: {epoch + 1}] [Batch idx: {batch_idx + 1}] train loss: {loss.item():.4f}' )\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型参数\n",
    "HIDDEN_SIZE = ?\n",
    "NUM_LAYERS = ?\n",
    "DROP_OUT = 0.0\n",
    "\n",
    "# 模型的保存路径\n",
    "SAVE_NAME = 'mechgru_params.pt'\n",
    "\n",
    "# 初始化训练参数，可以根据训练效果调整\n",
    "NUM_EPOCHS = ?                # 迭代次数，建议100次以上\n",
    "TOTAL_STEPS = TRAIN_SIZE // TRAIN_BATCH_SIZE * NUM_EPOCHS\n",
    "STEP_SIZE = TOTAL_STEPS // 4\n",
    "LR = ?                        # 初始学习率，建议0.0001~0.001\n",
    "\n",
    "# 初始化model和optimizer\n",
    "# 选择MSELoss作为criterion(其他度量也可)\n",
    "# 选择nn.Tanh()作为激活函数\n",
    "# 选择lr_scheduler.StepLR作为lr_scheduler，设置step_size=STEP_SIZE\n",
    "##### your code here #####\n",
    "activation = ?\n",
    "model = ?\n",
    "##### 如果有gpu，注意放到gpu上进行计算 #####\n",
    "model.to(device)\n",
    "optimizer = ?\n",
    "criterion = ?\n",
    "lr_scheduler = ?\n",
    "\n",
    "# 输出\n",
    "NUM_LOG = TOTAL_STEPS // 20\n",
    "print(f\"总训练轮次: {NUM_EPOCHS}, 总训练步数: {TRAIN_SIZE//TRAIN_BATCH_SIZE * NUM_EPOCHS}\")\n",
    "print(f\"学习率每{STEP_SIZE}步进行调整, 每{NUM_LOG}步输出当前loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2669c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行训练并保存结果\n",
    "# 根据配置和训练参数，训练需要5-30分钟，若时间过长可调大batch_size,减小epochs\n",
    "train_loss = ?\n",
    "torch.save(model.state_dict( ), SAVE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练过程的loss变化情况，一般是迅速下降-缓慢下降-收敛的曲线\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('train batch')\n",
    "plt.ylabel('train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试函数\n",
    "def test(model, data_loader, criterion):\n",
    "    \"\"\"\n",
    "    在这里定义一个测试模块函数\n",
    "    参数：\n",
    "        model(nn.Module):模型\n",
    "        data_loader(DataLoader):用于加载测试数据的loader\n",
    "        criterion:评估测试结果的损失函数\n",
    "    输出：\n",
    "        eval_loss(list[float]):记录每批次测试数据的评估loss的列表\n",
    "        results(list[(src, tgt, pt)]):一个列表，其中每个元素记录一个批次的src,tgt,pt，pt表示prediction\n",
    "    提示：\n",
    "       对数据批次进行循环\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    results = []\n",
    "    \n",
    "    for batch_idx, (src, tgt) in enumerate(data_loader):\n",
    "        ##### your code here #####\n",
    "        ##### you need to calculate loss and prediction #####\n",
    "\n",
    "        # 输出当前评估结果\n",
    "        print(f'[Batch idx: {batch_idx + 1}] eval loss: {loss.item():.4f}' )\n",
    "        \n",
    "    return eval_loss, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f581916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练的模型进行评估\n",
    "saved_dict = torch.load(SAVE_NAME)\n",
    "model.load_state_dict(saved_dict)\n",
    "eval_loss, results = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机绘制一部分结果：\n",
    "select = random.sample(results, 4)\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    \n",
    "    # 还原为初始数据分布\n",
    "    src, tgt, pt = select[i]\n",
    "    src = ?\n",
    "    tgt = ?\n",
    "    pt = ?\n",
    "    \n",
    "    # 转化成numpy的array方便绘图\n",
    "    src = src[0, :, 0].cpu().numpy()\n",
    "    tgt = tgt[0, :, 0].cpu().numpy()\n",
    "    pt = pt[0, :, 0].detach().cpu().numpy()\n",
    "    \n",
    "    # 理论曲线用黑色实线表示\n",
    "    plt.plot(src, tgt, color='black', linestyle='solid', label='target')\n",
    "    # 预测曲线用红色虚线表示\n",
    "    plt.plot(src, pt, color='red', linestyle='dashed', label='prediction')\n",
    "    plt.xlabel('src')\n",
    "    plt.ylabel('tgt/pt')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f6240",
   "metadata": {},
   "source": [
    "# 更多思考\n",
    "请思考并试验以下因素对模型效果的影响，尝试进一步优化模型:\n",
    "\n",
    "1、数据方面：数据选取，数据量，数据集划分，序列长度，数据预处理方法等\n",
    "\n",
    "2、模型方面：模型参数（hidden_size)，GRU层数（num_layers)，模型结构，是否有线性层，激活函数等\n",
    "\n",
    "3、训练方面：每批数据量（batch_size），训练轮次（num_epochs)，初始学习率（LR)，学习率调整策略，优化器选择等\n",
    "\n",
    "4、力学方面：结合预测曲线和理论结果的差异，分析如何使模型更好地模拟力学行为。\n",
    "\n",
    "欢迎各位保持交流，谢谢！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
